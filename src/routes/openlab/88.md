---
layout: openlab
edition: 88
theme: "The Sophtar"
description: "Hands-on presentation of the Sophtar, a networkable feedback string instrument with embedded machine learning."
date: "2024-09-27"
highlight_image: "openlabs/sophtar-wide-web-ph-credit-Nikolaus-Brade.jpeg"
---

<script>
    import CaptionedImage from "../../components/Images/CaptionedImage.svelte"
</script>

<CaptionedImage
    src="images/openlabs/sophtar-wide-web-ph-credit-Nikolaus-Brade.jpeg"
    alt="A photo of the Sophtar, an unusual wooden string instrument with embedded electronics. The instrument lies on a black hard case and there are two chopsticks a keyboard and a screen next to it." 
    caption="The Sophtar. Photo: Nikolaus Brade."/>

# The Sophtar: a networkable feedback string instrument with embedded machine learning

The Sophtar is a tabletop string instrument with an embedded system for digital signal processing, networking, and machine learning. It features a pressure-sensitive fretted neck, two sound boxes, and controlled feedback capabilities by means of bespoke interface elements. The design of the instrument is informed by my practice with hyperorgan interaction in networked music performance. During the open lab, I will show the instrument, demonstrate some of its musical affordances, and describe the hyperorgan and sound synthesis interactions approaches it implements. In particular, I will show some very recent developments that are part of my work at IIL: an extension that allows the instrument to self-play by means of solenoids, embedding [notochord](https://intelligent-instruments-lab.github.io/notochord/) models, and per-string filtering for harmonic feedback.

<CaptionedImage
    src="images/openlabs/Federico-Visi-Sophtar-ph-credit-Christian-Kielmann.jpg"
    alt="A photo of Federico Visi playing the Sophtar." 
    caption="Federico Visi playing the Sophtar. Photo: Christian-Kielmann."/>

# Federico Visi

I am a researcher, composer, and performer. I am interested in the interplay between human and artificial agencies in music, the role of body movement in performing with musical instruments, networked music performance, and interactive machine learning in musical instrument design. I have recently designed a networkable feedback string instrument with embedded machine learning called the Sophtar. At IIL I am working on extending the Sophtar with actuators and machine learning models to make it respond to my playing in ways that are not easy to predict yet meaningful and inspiring. I see the research and development work on the Sophtar as a way to probe and engage with broader research questions on musical improvisation and co-creativity with machines and algorithms. Aside from my work at IIL, I am a senior researcher at Luleå University of Technology where I am part of the “GEMM))) Gesture Embodiment and Machines in Music” research cluster, and I research and teach at Universität der Künste Berlin where I am part of the Wearable Computing Group at the Berlin Open Lab. I am a member of TCP/Indeterminate Place (TCP/IP), a quartet whose practice is focused on networked performance with remotely controlled hyperorgans. Under the moniker AQAXA, I have released an EP in which I combine conventional electronic music production techniques with the exploration of personal sonic memories by means of body movement and machine learning algorithms.

[www.federicovisi.com](http://www.federicovisi.com)
